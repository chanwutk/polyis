#!/usr/local/bin/python

import argparse
import json
import os
import cv2
import numpy as np
from tqdm import tqdm
import shutil
import time
from typing import NamedTuple, Tuple
from queue import Queue


DATA_DIR = '/polyis-data/video-datasets-low'
CACHE_DIR = '/polyis-cache'
# TILE_SIZES = [32, 64, 128]
TILE_SIZES = [64]


class PolyominoMapping(NamedTuple):
    """Mapping information for packed polyominoes."""
    index_map: np.ndarray  # Shape: (height//chunk_size, width//chunk_size, 2)
    det_info: dict  # Maps (frame_idx, group_id) to ((y, x), offset)
    frame_idx: int
    frame_cache: dict  # Maps frame_idx to frame
    canvas: np.ndarray  # The packed image
    frame_range: slice  # Range of frames in this packed image


def parse_args():
    """
    Parse command line arguments for the script.
    
    Returns:
        argparse.Namespace: Parsed command line arguments containing:
            - dataset (str): Dataset name to process (default: 'b3d')
            - tile_size (int | str): Tile size to use for packing (choices: 64, 128, 'all')
            - groundtruth (bool): Whether to use groundtruth scores (score_correct.jsonl) instead of model scores (score.jsonl)
            - threshold (float): Threshold for classification probability (default: 0.5)
    """
    parser = argparse.ArgumentParser(description='Execute packing of video tiles into images based on classification results')
    parser.add_argument('--dataset', required=False,
                        default='b3d',
                        help='Dataset name')
    parser.add_argument('--tile_size', type=str, choices=['64', '128', 'all'], default='all',
                        help='Tile size to use for packing (or "all" for all tile sizes)')
    parser.add_argument('--groundtruth', action='store_true',
                        help='Use groundtruth scores (score_correct.jsonl) instead of model scores (score.jsonl)')
    parser.add_argument('--threshold', type=float, default=0.5,
                        help='Threshold for classification probability (0.0 to 1.0)')
    return parser.parse_args()


def load_classification_results(cache_dir: str, dataset: str, video_file: str, tile_size: int, groundtruth: bool = False) -> list:
    """
    Load classification results from the JSONL file generated by 020_exec_classify.py.
    
    Args:
        cache_dir (str): Cache directory path
        dataset (str): Dataset name
        video_file (str): Video file name
        tile_size (int): Tile size used for classification
        groundtruth (bool): Whether to use groundtruth scores (score_correct.jsonl) instead of model scores (score.jsonl)
        
    Returns:
        list: List of frame classification results, each containing frame data and classifications
        
    Raises:
        FileNotFoundError: If no classification results file is found
    """
    # Look for the classification results file
    score_dir = os.path.join(cache_dir, dataset, video_file, 'relevancy', 'score', f'proxy_{tile_size}')
    
    # Determine which filename to look for based on groundtruth flag
    if groundtruth:
        expected_filename = 'score_correct.jsonl'
    else:
        expected_filename = 'score.jsonl'
    
    # Look for the specific results file
    results_file = os.path.join(score_dir, expected_filename)
    
    if not os.path.exists(results_file):
        raise FileNotFoundError(f"Classification results file not found: {results_file}")
    
    print(f"Loading classification results from: {results_file}")
    
    results = []
    with open(results_file, 'r') as f:
        for line in f:
            if line.strip():
                results.append(json.loads(line))
    
    print(f"Loaded {len(results)} frame classifications")
    return results


def find_connected_tiles(bitmap: np.ndarray, i: int, j: int) -> list[Tuple[int, int]]:
    """
    Find all connected tiles in the bitmap starting from the tile at (i, j).
    
    Args:
        bitmap: 2D numpy array representing the grid of tiles,
                where 1 indicates a tile with detection and 0 indicates no detection
        i: row index of the starting tile
        j: column index of the starting tile
        
    Returns:
        list[Tuple[int, int]]: List of tuples representing the coordinates of all connected tiles
    """
    value = bitmap[i, j]
    q = Queue()
    q.put((i, j))
    filled: list[tuple[int, int]] = []
    while not q.empty():
        i, j = q.get()
        bitmap[i, j] = value
        filled.append((i, j))
        for _i, _j in [(-1, 0), (0, -1), (+1, 0), (0, +1)]:
            _i += i
            _j += j
            if bitmap[_i, _j] != 0 and bitmap[_i, _j] != value:
                q.put((_i, _j))
    return filled


def group_tiles(bitmap: np.ndarray) -> list[Tuple[int, np.ndarray, Tuple[int, int]]]:
    """
    Group groups of connected tiles into polyominoes.
    
    Args:
        bitmap: 2D numpy array representing the grid of tiles,
                where 1 indicates a tile with detection and 0 indicates no detection
                
    Returns:
        list[Tuple[int, np.ndarray, Tuple[int, int]]]: List of polyominoes, where each polyomino is:
            - group_id: unique id of the group
            - mask: masking of the polyomino as a 2D numpy array
            - offset: offset of the mask from the top left corner of the bitmap
    """
    h, w = bitmap.shape
    _groups = np.arange(h * w, dtype=np.int32) + 1
    _groups = _groups.reshape(bitmap.shape)
    _groups = _groups * bitmap
    
    # Padding with size=1 on all sides
    groups = np.zeros((h + 2, w + 2), dtype=np.int32)
    groups[1:h+1, 1:w+1] = _groups
    
    visited: set[int] = set()
    bins: list[Tuple[int, np.ndarray, Tuple[int, int]]] = []
    
    for i in range(groups.shape[0]):
        for j in range(groups.shape[1]):
            if groups[i, j] == 0 or groups[i, j] in visited:
                continue
            
            connected_tiles = find_connected_tiles(groups, i, j)
            if not connected_tiles:
                continue
                
            connected_tiles = np.array(connected_tiles, dtype=int).T
            mask = np.zeros((h + 1, w + 1), dtype=np.bool)
            mask[*connected_tiles] = True
            
            offset = np.min(connected_tiles, axis=1)
            end = np.max(connected_tiles, axis=1) + 1
            
            mask = mask[offset[0]:end[0], offset[1]:end[1]]
            bins.append((groups[i, j], mask, (int(offset[0] - 1), int(offset[1] - 1))))
            visited.add(groups[i, j])
    
    return bins


class PackingFailedException(Exception):
    """Exception raised when packing fails."""



def pack_append(bins: list[Tuple[int, np.ndarray, Tuple[int, int]]], 
                h: int, w: int, 
                bitmap: np.ndarray | None = None) -> Tuple[np.ndarray, list] | None:
    """
    Pack polyominoes into a bitmap.
    
    Args:
        bins: List of polyominoes to pack
        h: Height of the bitmap
        w: Width of the bitmap
        bitmap: Existing bitmap to append to (None for new)
        
    Returns:
        Tuple[np.ndarray, list]: (bitmap, positions) where positions contains packing info
    """
    new_bitmap = False
    if bitmap is None:
        bitmap = np.zeros((h, w), dtype=np.bool)
        new_bitmap = True
    else:
        bitmap = bitmap.copy()
    
    if len(bins) == 0:
        return bitmap, []
    
    positions: list[Tuple[int, int, int, np.ndarray, Tuple[int, int]]] = []
    
    for groupid, mask, offset in bins:
        for j in range(w - mask.shape[1] + 1):
            for i in range(h - mask.shape[0] + 1):
                if not np.any(bitmap[i:i+mask.shape[0], j:j+mask.shape[1]] & mask):
                    bitmap[i:i+mask.shape[0], j:j+mask.shape[1]] |= mask
                    positions.append((i, j, groupid, mask, offset))
                    break
            else:
                continue
            break
        else:
            return None
    
    return bitmap, positions


def render(canvas: np.ndarray, positions: list[Tuple[int, int, int, np.ndarray, Tuple[int, int]]], 
           frame: np.ndarray, chunk_size: int) -> np.ndarray:
    """
    Render packed polyominoes onto the canvas.
    
    Args:
        canvas: The canvas to render onto
        positions: List of packed polyominoe positions
        frame: Source frame
        chunk_size: Size of each tile/chunk
        
    Returns:
        np.ndarray: Updated canvas
    """
    for y, x, groupid, mask, offset in positions:
        yfrom, yto = y * chunk_size, (y + mask.shape[0]) * chunk_size
        xfrom, xto = x * chunk_size, (x + mask.shape[1]) * chunk_size
        
        for i in range(mask.shape[0]):
            for j in range(mask.shape[1]):
                if mask[i, j]:
                    patch = frame[
                        (i + offset[0]) * chunk_size:(i + offset[0] + 1) * chunk_size,
                        (j + offset[1]) * chunk_size:(j + offset[1] + 1) * chunk_size,
                    ]
                    canvas[
                        yfrom + (chunk_size * i): yfrom + (chunk_size * i) + chunk_size,
                        xfrom + (chunk_size * j): xfrom + (chunk_size * j) + chunk_size,
                    ] = patch
    
    return canvas


def apply_pack(pack_results: Tuple[np.ndarray, list], canvas: np.ndarray, index_map: np.ndarray,
               det_info: dict, frame_idx: int, frame: np.ndarray, tile_size: int, step_times: dict):
    bitmap, positions = pack_results
    
    # Profile: Render packed polyominoes onto canvas
    step_start = time.time()
    canvas = render(canvas, positions, frame, tile_size)
    step_times['render_canvas'] = time.time() - step_start

    assert index_map is not None
    
    # Profile: Update index_map and det_info
    step_start = time.time()
    for gid, (y, x, _groupid, mask, _offset) in enumerate(positions):
        assert not np.any(index_map[y:y+mask.shape[0], x:x+mask.shape[1], 0] & mask), (index_map[y:y+mask.shape[0], x:x+mask.shape[1], 0], mask)
        index_map[y:y+mask.shape[0], x:x+mask.shape[1], 0] += mask.astype(np.int32) * (gid + 1)
        index_map[y:y+mask.shape[0], x:x+mask.shape[1], 1] += mask.astype(np.int32) * frame_idx
        det_info[(int(frame_idx), int(gid + 1))] = ((y, x), _offset)
    step_times['update_mapping'] = time.time() - step_start

    return bitmap, canvas


def process_video_packing(video_path: str, results: list, tile_size: int, output_dir: str, threshold: float = 0.5):
    """
    Process a single video for packing based on classification results.
    
    Args:
        video_path (str): Path to the input video file
        results (list): List of classification results
        tile_size (int): Tile size used for processing
        output_dir (str): Directory to save packing results
        threshold (float): Threshold for classification probability (0.0 to 1.0)
    """
    print(f"Processing video for packing: {video_path}")
    
    # Open video to get dimensions and initialize capture
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Error: Could not open video {video_path}")
        return
    
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # Calculate grid dimensions
    grid_height = height // tile_size
    grid_width = width // tile_size
    
    # Initialize packing variables
            
    canvas = np.zeros((height, width, 3), dtype=np.uint8)
    bitmap: np.ndarray | None = None
    index_map = np.zeros((grid_height, grid_width, 2), dtype=np.int32)
    det_info: dict = {}
    frame_cache = {}
    start_idx = 0
    pack_idx = 0
    last_frame_idx = -1
    read_frame_idx = -1
    
    # Initialize profiling output file
    runtime_file = os.path.join(output_dir, '..', 'runtime.jsonl')
    
    print(f"Processing {len(results)} frames with tile size {tile_size}")
    
    # Process each frame
    for frame_idx, frame_result in enumerate(tqdm(results, desc="Packing frames")):
        # Start profiling for this frame
        frame_start_time = time.time()
        step_times = {}
        
        # Assert that frame_idx is increasing
        assert frame_idx > last_frame_idx, f"Frame index must be increasing, got {frame_idx} after {last_frame_idx}"
        last_frame_idx = frame_idx
            
        # Profile: Read frame from video
        step_start = time.time()
        ret = False
        frame = None
        while read_frame_idx < frame_idx:
            ret, frame = cap.read()
            read_frame_idx += 1
        assert ret and frame is not None
        frame_cache[frame_idx] = frame
        step_times['read_frame'] = time.time() - step_start
        
        # Profile: Get classification results
        step_start = time.time()
        classifications = frame_result['tile_classifications']
        step_times['get_classifications'] = time.time() - step_start
        
        # Profile: Create bitmap from classifications
        step_start = time.time()
        bitmap_frame = np.array(classifications) > threshold
        bitmap_frame = bitmap_frame.astype(np.int32)
        step_times['create_bitmap'] = time.time() - step_start
        
        # Profile: Group connected tiles into polyominoes
        step_start = time.time()
        polyominoes = group_tiles(bitmap_frame.copy())
        step_times['group_tiles'] = time.time() - step_start
        
        # Profile: Sort polyominoes by size
        step_start = time.time()
        polyominoes = sorted(polyominoes, key=lambda x: x[1].sum(), reverse=True)
        step_times['sort_polyominoes'] = time.time() - step_start
        
        # Profile: Try packing polyominoes
        step_start = time.time()
        pack_results = pack_append(polyominoes, grid_height, grid_width, bitmap)

        if pack_results is not None:
            step_times['pack_append'] = time.time() - step_start
            bitmap, canvas = apply_pack(pack_results, canvas, index_map, det_info,
                                        frame_idx, frame, tile_size, step_times)
        else:
            # If packing fails, save current packed image and start new one
            step_times['pack_failed'] = True
            step_times['pack_append_failed'] = time.time() - step_start
            
            assert canvas is not None and index_map is not None

            # Profile: Save current packed image
            step_start = time.time()
            img_path = os.path.join(output_dir, f'img_{pack_idx:08d}.jpg')
            cv2.imwrite(img_path, canvas)
            step_times['save_canvas'] = time.time() - step_start

            # Save mapping
            mapping = PolyominoMapping(
                index_map=index_map,
                det_info=det_info,
                frame_idx=frame_idx,
                frame_cache=frame_cache,
                canvas=canvas,
                frame_range=slice(start_idx, frame_idx)
            )

            # Profile: Convert numpy arrays to lists for JSON serialization
            step_start = time.time()
            mapping_dict = {
                'index_map': index_map.tolist(),
                'det_info': {str(k): v for k, v in det_info.items()},
                'frame_idx': mapping.frame_idx,
                'frame_cache_keys': list(mapping.frame_cache.keys()),
                'frame_range': [mapping.frame_range.start, mapping.frame_range.stop]
            }
            step_times['convert_to_dict'] = time.time() - step_start

            # Profile: Save mapping to file
            step_start = time.time()
            mapping_path = os.path.join(output_dir, f'mapping_{pack_idx:08d}.json')
            with open(mapping_path, 'w') as f:
                json.dump(mapping_dict, f, indent=2)
            step_times['save_mapping_file'] = time.time() - step_start

            # Reset for next packed image
            pack_idx += 1

            # Profile: Reset variables
            step_start = time.time()
            canvas = np.zeros((height, width, 3), dtype=np.uint8)
            bitmap = None
            index_map = np.zeros((grid_height, grid_width, 2), dtype=np.int32)
            det_info = {}
            frame_cache = {frame_idx: frame_cache.get(frame_idx, np.zeros((height, width, 3), dtype=np.uint8))}
            start_idx = frame_idx
            step_times['reset_variables'] = time.time() - step_start

            # Profile: Retry packing for current frame
            step_start = time.time()
            pack_results = pack_append(polyominoes, grid_height, grid_width)
            if pack_results is not None:
                step_times['pack_append'] = time.time() - step_start
                bitmap, canvas = apply_pack(pack_results, canvas, index_map, det_info,
                                            frame_idx, frame, tile_size, step_times)
            else:
                step_times['pack_failed_retry'] = True
                step_times['pack_append_failed_retry'] = time.time() - step_start

                # If retry packing fails, save the entire frame as a single polyomino
                print(f"Failed to pack frame {frame_idx} even after reset, saving entire frame as single polyomino")

                # Create a single polyomino covering the entire frame
                # full_frame_mask = np.ones((grid_height, grid_width), dtype=np.bool)
                
                # Render the entire frame onto canvas
                # canvas = render(canvas, [(0, 0, 1, full_frame_mask, (0, 0))], frame_cache[frame_idx], tile_size)
                canvas = frame_cache[frame_idx]

                # Profile: Update index_map and det_info for the full frame polyomino
                step_start = time.time()
                bitmap = np.ones((grid_height, grid_width), dtype=np.bool)
                index_map[0:grid_height, 0:grid_width, 0] = 1
                index_map[0:grid_height, 0:grid_width, 1] = frame_idx
                det_info[(int(frame_idx), int(1))] = ((0, 0), (0, 0))
                step_times['update_mapping'] = time.time() - step_start

        # Calculate total frame processing time
        step_times['total_frame_time'] = time.time() - frame_start_time
        
        # Save profiling data for this frame
        profiling_data = {
            'frame_idx': frame_idx,
            'step_times': step_times,
            'num_polyominoes': len(polyominoes) if 'polyominoes' in locals() else 0,
            'packing_success': 'handle_packing_failure' not in step_times
        }
        
        with open(runtime_file, 'a') as f:
            f.write(json.dumps(profiling_data) + '\n')
    
    # Release video capture
    cap.release()
    
    # Save final packed image if exists
    if canvas is not None and index_map is not None:
        img_path = os.path.join(output_dir, f'img_{pack_idx:03d}.jpg')
        cv2.imwrite(img_path, canvas)
        
        mapping = PolyominoMapping(
            index_map=index_map,
            det_info=det_info,
            frame_idx=len(results),
            frame_cache=frame_cache,
            canvas=canvas,
            frame_range=slice(start_idx, len(results))
        )
        
        mapping_dict = {
            'index_map': index_map.tolist(),
            'det_info': {str(k): v for k, v in det_info.items()},
            'frame_idx': mapping.frame_idx,
            'frame_cache_keys': list(mapping.frame_cache.keys()),
            'frame_range': [mapping.frame_range.start, mapping.frame_range.stop]
        }
        
        mapping_path = os.path.join(output_dir, f'mapping_{pack_idx:03d}.json')
        with open(mapping_path, 'w') as f:
            json.dump(mapping_dict, f, indent=2)
        
        # print(f"Saved final packed image {pack_idx} with {len(det_info)} polyominoes")
    
    print(f"Completed packing for video. Created {pack_idx + 1} packed images.")
    print(f"Runtime profiling data saved to: {runtime_file}")


def main(args):
    """
    Main function that orchestrates the video tile packing process.
    
    This function serves as the entry point for the script. It:
    1. Validates the dataset directory exists
    2. Iterates through all videos in the dataset directory
    3. For each video, loads classification results for the specified tile size(s)
    4. Groups connected tiles into polyominoes and packs them into images
    5. Saves packed images and their mappings
    
    Args:
        args (argparse.Namespace): Parsed command line arguments containing:
            - dataset (str): Name of the dataset to process
            - tile_size (str): Tile size to use for packing ('64', '128', or 'all')
            - groundtruth (bool): Whether to use groundtruth scores (score_correct.jsonl) instead of model scores (score.jsonl)
            - threshold (float): Threshold for classification probability (0.0 to 1.0)
            
    Note:
        - The script expects classification results from 020_exec_classify.py in:
          {CACHE_DIR}/{dataset}/{video_file}/relevancy/score/proxy_{tile_size}/
        - When groundtruth=True, looks for score_correct.jsonl files
        - When groundtruth=False, looks for score.jsonl files
        - Videos are read from {DATA_DIR}/{dataset}/
        - Packed images are saved to {CACHE_DIR}/{dataset}/{video_file}/packing/img_{pack_idx}.jpg
        - Mappings are saved to {CACHE_DIR}/{dataset}/{video_file}/packing/mapping_{pack_idx}.json
        - When tile_size is 'all', all two tile sizes (64, 128) are processed
        - If no classification results are found for a video, that video is skipped with a warning
        - Tiles with classification probability > threshold are considered relevant for packing
    """
    dataset_dir = os.path.join(DATA_DIR, args.dataset)
    
    if not os.path.exists(dataset_dir):
        raise FileNotFoundError(f"Dataset directory {dataset_dir} does not exist")
    
    # Determine which tile sizes to process
    if args.tile_size == 'all':
        tile_sizes_to_process = TILE_SIZES
        print(f"Processing all tile sizes: {tile_sizes_to_process}")
    else:
        tile_sizes_to_process = [int(args.tile_size)]
        print(f"Processing tile size: {tile_sizes_to_process[0]}")
    
    # Get all video files from the dataset directory
    video_files = [f for f in os.listdir(dataset_dir) if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]
    
    if not video_files:
        print(f"No video files found in {dataset_dir}")
        return
    
    print(f"Found {len(video_files)} video files to process")
    
    # Process each video file
    for video_file in sorted(video_files):
        video_file_path = os.path.join(dataset_dir, video_file)
        
        print(f"\nProcessing video file: {video_file}")
        
        # Process each tile size for this video
        for tile_size in tile_sizes_to_process:
            print(f"Processing tile size: {tile_size}")
            
            try:
                # Load classification results
                results = load_classification_results(CACHE_DIR, args.dataset, video_file, tile_size, args.groundtruth)
                
                # Create output directory for packing results
                packing_output_dir = os.path.join(CACHE_DIR, args.dataset, video_file, 'packing', f'proxy_{tile_size}')
                if os.path.exists(packing_output_dir):
                    # Remove the entire directory
                    shutil.rmtree(packing_output_dir)
                os.makedirs(packing_output_dir)

                packing_output_dir = os.path.join(packing_output_dir, 'images')
                if os.path.exists(packing_output_dir):
                    # Remove the entire directory
                    shutil.rmtree(packing_output_dir)
                os.makedirs(packing_output_dir)
                
                # Process the video for packing
                process_video_packing(video_file_path, results, tile_size, packing_output_dir, args.threshold)
                
                print(f"Completed packing for tile size {tile_size}")
                
            except FileNotFoundError as e:
                print(f"Warning: {e}, skipping tile size {tile_size} for video {video_file}")
                raise e
            except Exception as e:
                print(f"Error processing tile size {tile_size} for video {video_file}: {e}")
                raise e


if __name__ == '__main__':
    main(parse_args())
