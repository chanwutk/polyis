#!/usr/local/bin/python

import argparse
import json
import os
import numpy as np
from tqdm import tqdm
import multiprocessing as mp

from modules.b3d.b3d.external.sort import Sort

CACHE_DIR = '/polyis-cache'
DATA_DIR = '/polyis-data/video-datasets-low'


def parse_args():
    """
    Parse command line arguments for the script.
    
    Returns:
        argparse.Namespace: Parsed command line arguments containing:
            - dataset (str): Dataset name to process (default: 'b3d')
            - tracker (str): Tracking algorithm to use (default: 'sort')
            - max_age (int): Maximum age for SORT tracker (default: 1)
            - min_hits (int): Minimum hits for SORT tracker (default: 3)
            - iou_threshold (float): IOU threshold for SORT tracker (default: 0.3)
    """
    parser = argparse.ArgumentParser(description='Execute object tracking on detection results')
    parser.add_argument('--dataset', required=False,
                        default='b3d',
                        help='Dataset name')
    parser.add_argument('--tracker', required=False,
                        default='sort',
                        choices=['sort'],
                        help='Tracking algorithm to use')
    parser.add_argument('--max_age', type=int, default=10,
                        help='Maximum age for SORT tracker')
    parser.add_argument('--min_hits', type=int, default=3,
                        help='Minimum hits for SORT tracker')
    parser.add_argument('--iou_threshold', type=float, default=0.3,
                        help='IOU threshold for SORT tracker')
    return parser.parse_args()


def load_detection_results(cache_dir: str, dataset: str, video_file: str) -> list[dict]:
    """
    Load detection results from the JSONL file generated by 001_preprocess_groundtruth_detection.py.
    
    Args:
        cache_dir (str): Cache directory path
        dataset (str): Dataset name
        video_file (str): Video file name
        
    Returns:
        list[dict]: list of frame detection results
        
    Raises:
        FileNotFoundError: If no detection results file is found
    """
    detection_path = os.path.join(cache_dir, dataset, video_file, 'groundtruth', 'detection.jsonl')
    
    if not os.path.exists(detection_path):
        raise FileNotFoundError(f"Detection results not found: {detection_path}")
    
    print(f"Loading detection results from: {detection_path}")
    
    results = []
    with open(detection_path, 'r') as f:
        for line in f:
            if line.strip():
                results.append(json.loads(line))
    
    print(f"Loaded {len(results)} frame detections")
    return results


def create_tracker(tracker_name: str, max_age: int = 1, min_hits: int = 3, iou_threshold: float = 0.3):
    """
    Create a tracker instance based on the specified algorithm.
    
    Args:
        tracker_name (str): Name of the tracking algorithm
        max_age (int): Maximum age for SORT tracker
        min_hits (int): Minimum hits for SORT tracker
        iou_threshold (float): IOU threshold for SORT tracker
        
    Returns:
        Tracker instance
        
    Raises:
        ValueError: If the tracker name is not supported
    """
    if tracker_name == 'sort':
        print(f"Creating SORT tracker with max_age={max_age}, min_hits={min_hits}, iou_threshold={iou_threshold}")
        return Sort(max_age=max_age, min_hits=min_hits, iou_threshold=iou_threshold)
    else:
        raise ValueError(f"Unknown tracker: {tracker_name}")


def interpolate_trajectory(trajectory: list[tuple[int, np.ndarray]], nxt: tuple[int, np.ndarray]) -> list[tuple[int, np.ndarray]]:
    """
    Perform linear interpolation between two trajectory points.
    
    Args:
        trajectory (list[tuple[int, np.ndarray]]): list of (frame_idx, detection) tuples
        nxt (tuple[int, np.ndarray]): Next detection point (frame_idx, detection)
        
    Returns:
        list[tuple[int, np.ndarray]]: list of interpolated points including the next point
    """
    extend: list[tuple[int, np.ndarray]] = []
    
    if len(trajectory) != 0:
        prv = trajectory[-1]
        assert prv[0] < nxt[0]
        prv_det = prv[1]
        nxt_det = nxt[1]
        dif_det = nxt_det - prv_det
        dif_det = dif_det.reshape(1, -1)

        scale = np.arange(0, nxt[0] - prv[0], dtype=np.float32).reshape(-1, 1) / (nxt[0] - prv[0])
        
        int_dets = (scale @ dif_det) + prv_det.reshape(1, -1)

        for idx, int_det in enumerate(int_dets[:-1]):
            extend.append((prv[0] + idx + 1, int_det))
    
    extend.append(nxt)
    return extend


def track_objects_in_video(video_file: str, detection_results: list[dict], tracker_name: str, 
                           max_age: int, min_hits: int, iou_threshold: float, output_path: str):
    """
    Execute object tracking on detection results and save tracking results to JSONL.
    
    Args:
        video_file (str): Name of the video file being processed
        detection_results (list[dict]): list of detection results from load_detection_results
        tracker_name (str): Name of the tracking algorithm
        max_age (int): Maximum age for SORT tracker
        min_hits (int): Minimum hits for SORT tracker
        iou_threshold (float): IOU threshold for SORT tracker
        output_path (str): Path where the output JSONL file will be saved
    """
    print(f"Processing video: {video_file}")
    
    # Create tracker
    tracker = create_tracker(tracker_name, max_age, min_hits, iou_threshold)
    
    # Initialize tracking data structures
    trajectories: dict[int, list[tuple[int, np.ndarray]]] = {}
    frame_tracks: dict[int, list[list[float]]] = {}
    
    print(f"Processing {len(detection_results)} frames for tracking...")
    
    # Process each frame
    for frame_result in tqdm(detection_results, desc="Tracking objects"):
        frame_idx = frame_result['frame_idx']
        detections = frame_result['detections']
        
        # Convert detections to numpy array format expected by SORT
        if detections:
            # SORT expects format: [[x1, y1, x2, y2, score], ...]
            dets = np.array(detections)
            if dets.size > 0:
                # Ensure we have the right format
                if dets.shape[1] >= 5:
                    dets = dets[:, :5]  # Take first 5 columns: x1, y1, x2, y2, score
                else:
                    # If we don't have scores, add default score of 1.0
                    dets = np.column_stack([dets, np.ones(dets.shape[0])])
            else:
                dets = np.empty((0, 5))
        else:
            dets = np.empty((0, 5))
        
        # Update tracker
        trackers = tracker.update(dets)
        
        # Process tracking results
        if trackers.size > 0:
            for track in trackers:
                # SORT returns: [x1, y1, x2, y2, track_id]
                x1, y1, x2, y2, track_id = track
                track_id = int(track_id)
                
                # Convert to detection format: [track_id, x1, y1, x2, y2]
                detection = [track_id, x1, y1, x2, y2]
                
                # Add to frame tracks
                if frame_idx not in frame_tracks:
                    frame_tracks[frame_idx] = []
                # frame_tracks[frame_idx].append(detection)

                if track_id not in trajectories:
                    trajectories[track_id] = []
                box_array = np.array([x1, y1, x2, y2], dtype=np.float32)

                
                extend = interpolate_trajectory(trajectories[track_id], (frame_idx, box_array))
                
                # Add interpolated points to frame tracks
                for e in extend:
                    e_frame_idx, e_box = e
                    if e_frame_idx not in frame_tracks:
                        frame_tracks[e_frame_idx] = []
                    
                    # Convert back to list format: [track_id, x1, y1, x2, y2]
                    e_detection = [track_id, *e_box.tolist()]
                    frame_tracks[e_frame_idx].append(e_detection)

                    # Add interpolated points to trajectories
                    trajectories[track_id].append((e_frame_idx, e_box))

        # Handle frames with no detections
        if frame_idx not in frame_tracks:
            frame_tracks[frame_idx] = []
    
    print(f"Tracking completed. Found {len(trajectories)} unique tracks.")
    
    # Save tracking results
    print(f"Saving tracking results to: {output_path}")
    
    # Create output directory if it doesn't exist
    output_dir = os.path.dirname(output_path)
    os.makedirs(output_dir, exist_ok=True)
    
    with open(output_path, 'w') as f:
        frame_ids = frame_tracks.keys()
        first_idx = min(frame_ids)
        last_idx = max(frame_ids)

        for frame_idx in range(first_idx, last_idx + 1):
            if frame_idx not in frame_tracks:
                frame_tracks[frame_idx] = []
                
            frame_data = {
                "frame_idx": frame_idx,
                "tracks": frame_tracks[frame_idx]
            }
            f.write(json.dumps(frame_data) + '\n')
    
    print(f"Tracking results saved successfully. Total frames: {len(frame_tracks)}")


def process_video_tracking(video_file: str, args, cache_dir: str, dataset: str):
    """
    Process tracking for a single video file.
    
    Args:
        video_file (str): Name of the video file to process
        args: Command line arguments
        cache_dir (str): Cache directory path
        dataset (str): Dataset name
    """
    try:
        # Load detection results
        detection_results = load_detection_results(cache_dir, dataset, video_file)
        
        # Create output path for tracking results
        output_path = os.path.join(cache_dir, dataset, video_file, 'groundtruth', 'tracking.jsonl')
        
        # Execute tracking
        track_objects_in_video(
            video_file, detection_results, args.tracker,
            args.max_age, args.min_hits, args.iou_threshold, output_path
        )
        
        print(f"Completed tracking for video: {video_file}")
        
    except Exception as e:
        print(f"Error processing video {video_file}: {e}")
        raise e


def main(args):
    """
    Main function that orchestrates the object tracking process.
    
    This function serves as the entry point for the script. It:
    1. Validates the dataset directory exists
    2. Finds all videos with detection results
    3. Creates a process pool for parallel processing
    4. Executes tracking on each video and saves results
    
    Args:
        args (argparse.Namespace): Parsed command line arguments
        
    Note:
        - The script expects detection results from 001_preprocess_groundtruth_detection.py in:
          {CACHE_DIR}/{dataset}/{video_file}/groundtruth/detection.jsonl
        - Tracking results are saved to:
          {CACHE_DIR}/{dataset}/{video_file}/groundtruth/tracking.jsonl
        - Linear interpolation is performed to fill missing detections in tracks
        - Processing is parallelized for improved performance
    """
    print(f"Processing dataset: {args.dataset}")
    print(f"Using tracker: {args.tracker}")
    print(f"Tracker parameters: max_age={args.max_age}, min_hits={args.min_hits}, iou_threshold={args.iou_threshold}")
    
    # Find all videos with detection results
    dataset_cache_dir = os.path.join(CACHE_DIR, args.dataset)
    if not os.path.exists(dataset_cache_dir):
        raise FileNotFoundError(f"Dataset cache directory {dataset_cache_dir} does not exist")
    
    # Look for directories that contain detection results
    video_dirs = []
    for item in os.listdir(dataset_cache_dir):
        item_path = os.path.join(dataset_cache_dir, item)
        if os.path.isdir(item_path):
            detection_path = os.path.join(item_path, 'groundtruth', 'detection.jsonl')
            if os.path.exists(detection_path):
                video_dirs.append(item)
    
    if not video_dirs:
        print(f"No videos with detection results found in {dataset_cache_dir}")
        return
    
    print(f"Found {len(video_dirs)} videos with detection results")
    
    # Determine number of processes to use
    num_processes = min(mp.cpu_count(), len(video_dirs), 40)  # Cap at 40 processes
    print(f"Using {num_processes} processes for parallel processing")
    
    # Create a pool of workers
    print(f"Creating process pool with {num_processes} workers...")
    
    # Prepare arguments for each video
    video_args = []
    for video_file in video_dirs:
        video_args.append((video_file, args, CACHE_DIR, args.dataset))
        print(f"Prepared video: {video_file}")
    
    # Use process pool to execute video tracking
    with mp.Pool(processes=num_processes) as pool:
        print(f"Starting video tracking with {num_processes} parallel workers...")
        
        # Map the work to the pool
        results = pool.starmap(process_video_tracking, video_args)
        
        print("All videos tracked successfully!")


if __name__ == '__main__':
    main(parse_args())
