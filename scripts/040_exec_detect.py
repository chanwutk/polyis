#!/usr/local/bin/python

import argparse
import json
import os
import shutil
import time
import cv2
import tqdm

import polyis.models.retinanet_b3d

CACHE_DIR = '/polyis-cache'
# TILE_SIZES = [32, 64, 128]
TILE_SIZES = [64]


def parse_args():
    """
    Parse command line arguments for the script.
    
    Returns:
        argparse.Namespace: Parsed command line arguments containing:
            - dataset (str): Dataset name to process (default: 'b3d')
            - tile_size (str): Tile size to use for detection (choices: '64', '128', 'all')
            - detector (str): Detector name to use (default: 'retina')
            - classifier (str): Classifier name to use (default: 'SimpleCNN')
    """
    parser = argparse.ArgumentParser(description='Detect objects from packed images generated by 030_exec_pack.py')
    parser.add_argument('--dataset', required=False,
                        default='b3d',
                        help='Dataset name')
    parser.add_argument('--tile_size', type=str, choices=['64', '128', 'all'], default='all',
                        help='Tile size to use for detection (or "all" for all tile sizes)')
    parser.add_argument('--detector', required=False,
                        default='retina',
                        help='Detector name')
    parser.add_argument('--classifier', type=str, default='SimpleCNN',
                        help='Classifier name to use (default: SimpleCNN)')
    return parser.parse_args()


def detect_retina_packed_images(video_file_path: str, tile_size: int, classifier: str):
    """
    Detect objects from packed images using RetinaNet detector.
    
    Args:
        video_file_path (str): Path to the video file
        tile_size (int): Tile size used for packing
        classifier (str): Classifier name used for packing
    """
    detector = polyis.models.retinanet_b3d.get_detector(device='cuda:0')

    print(f"Processing video {video_file_path}")

    # Check if packing directory exists for this tile size
    packing_dir = os.path.join(video_file_path, 'packing', f'{classifier}_{tile_size}', 'images')
    if not os.path.exists(packing_dir):
        raise FileNotFoundError(f"Packing directory not found for video {video_file_path} and tile size {tile_size}")

    # Create output directory for detections
    detections_output_dir = os.path.join(video_file_path, 'packed_detections', f'{classifier}_{tile_size}')
    if os.path.exists(detections_output_dir):
        # Remove the entire directory
        shutil.rmtree(detections_output_dir)
    os.makedirs(detections_output_dir, exist_ok=True)

    # Get all packed image files
    image_files = [f for f in os.listdir(packing_dir) if f.endswith('.jpg')]
    
    if not image_files:
        raise FileNotFoundError(f"No packed images found in {packing_dir}")

    with (open(os.path.join(detections_output_dir, 'detections.jsonl'), 'w') as f,
          open(os.path.join(detections_output_dir, 'runtimes.jsonl'), 'w') as fr):
        for image_file in tqdm.tqdm(image_files, desc=f"Processing packed images for tile size {tile_size}"):
            image_path = os.path.join(packing_dir, image_file)
            runtime: dict = { 'image_file': image_file }
            
            # Read the packed image
            start_time = (time.time_ns() / 1e6)
            frame = cv2.imread(image_path)
            if frame is None:
                raise ValueError(f"Could not read image {image_path}")
            end_time = (time.time_ns() / 1e6)
            runtime['read_time'] = end_time - start_time

            # Detect objects in the frame
            start_time = (time.time_ns() / 1e6)
            outputs = polyis.models.retinanet_b3d.detect(frame, detector)
            end_time = (time.time_ns() / 1e6)
            runtime['detect_time'] = end_time - start_time

            # Extract bounding boxes (x1, y1, x2, y2 format)
            bounding_boxes = outputs[:, :4].tolist()

            # Save detection results
            f.write(json.dumps({ 'image_file': image_file, 'bboxes': bounding_boxes }) + '\n')
            fr.write(json.dumps(runtime) + '\n')


def main(args):
    """
    Main function that orchestrates the object detection process on packed images.
    
    This function serves as the entry point for the script. It:
    1. Validates the dataset directory exists
    2. Iterates through all videos in the dataset directory
    3. For each video, finds packed images for the specified tile size(s)
    4. Detects objects in each packed image using the specified detector
    5. Saves detection results as JSONL files with bounding box coordinates
    
    Args:
        args (argparse.Namespace): Parsed command line arguments containing:
            - dataset (str): Name of the dataset to process
            - tile_size (str): Tile size to use for detection ('64', '128', or 'all')
            - detector (str): Name of the detector to use
            - classifier (str): Classifier name to use (default: 'SimpleCNN')
            
    Note:
        - The script expects packed images from 030_exec_pack.py in:
          {CACHE_DIR}/{dataset}/{video_file}/packing/{classifier}_{tile_size}/images/
        - Detection results are saved to:
          {CACHE_DIR}/{dataset}/{video_file}/packed_detections/{classifier}_{tile_size}/detections.jsonl
        - Each line in the output JSONL file contains one bounding box [x1, y1, x2, y2]
        - When tile_size is 'all', all available tile sizes are processed
        - If no packed images are found for a video/tile_size combination, that combination is skipped
    """
    dataset_dir = os.path.join(CACHE_DIR, args.dataset)
    
    if not os.path.exists(dataset_dir):
        raise FileNotFoundError(f"Dataset directory {dataset_dir} does not exist")
    
    # Determine which tile sizes to process
    if args.tile_size == 'all':
        tile_sizes_to_process = TILE_SIZES
    else:
        tile_sizes_to_process = [int(args.tile_size)]
    
    # Get all video files from the dataset directory
    video_files = [f for f in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, f))]
    
    # Process each video file
    for video_file in sorted(video_files):
        video_file_path = os.path.join(dataset_dir, video_file)
        
        print(f"\nProcessing video file: {video_file}")
        
        # Process each tile size for this video
        for tile_size in tile_sizes_to_process:
            if args.detector == 'retina':
                detect_retina_packed_images(video_file_path, tile_size, args.classifier)
            else:
                raise ValueError(f"Unknown detector: {args.detector}")


if __name__ == '__main__':
    main(parse_args())
