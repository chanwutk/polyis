#!/usr/local/bin/python

import argparse
import json
import os
import shutil
import time
import cv2
import tqdm

import polyis.models.retinanet_b3d
from scripts.utilities import CACHE_DIR, DATA_DIR, format_time


# TILE_SIZES = [30, 60, 120]
TILE_SIZES = [60]


def parse_args():
    """
    Parse command line arguments for the script.
    
    Returns:
        argparse.Namespace: Parsed command line arguments containing:
            - dataset (str): Dataset name to process (default: 'b3d')
            - tile_size (str): Tile size to use for detection (choices: '30', '60', '120', 'all')
            - detector (str): Detector name to use (default: 'retina')
            - classifier (str): Classifier name to use (choices: 'SimpleCNN', 'groundtruth', 'all'; default: 'SimpleCNN')
            - clear (bool): Whether to remove and recreate the packed_detections folder for each video (default: False)
    """
    parser = argparse.ArgumentParser(description='Detect objects from packed images generated by 030_exec_pack.py')
    parser.add_argument('--dataset', required=False,
                        default='b3d',
                        help='Dataset name')
    parser.add_argument('--tile_size', type=str, choices=['30', '60', '120', 'all'], default='all',
                        help='Tile size to use for detection (or "all" for all tile sizes)')
    parser.add_argument('--detector', required=False,
                        default='retina',
                        help='Detector name')
    parser.add_argument('--classifier', type=str, choices=['SimpleCNN', 'groundtruth', 'all'], default='SimpleCNN',
                        help='Classifier name to use (default: SimpleCNN, or "all" for both SimpleCNN and groundtruth)')
    parser.add_argument('--clear', action='store_true',
                        help='Remove and recreate the packed_detections folder for each video')
    return parser.parse_args()


def detect_retina_packed_images(video_file_path: str, tile_size: int, classifier: str):
    """
    Detect objects from packed images using RetinaNet detector.
    
    Args:
        video_file_path (str): Path to the video file
        tile_size (int): Tile size used for packing
        classifier (str): Classifier name used for packing
    """
    detector = polyis.models.retinanet_b3d.get_detector(device='cuda')

    print(f"Processing video {video_file_path}")

    # Check if packing directory exists for this tile size
    packing_dir = os.path.join(video_file_path, 'packing', f'{classifier}_{tile_size}', 'images')
    if not os.path.exists(packing_dir):
        raise FileNotFoundError(f"Packing directory not found for video {video_file_path} and tile size {tile_size}")

    # Create output directory for detections
    detections_output_dir = os.path.join(video_file_path, 'packed_detections', f'{classifier}_{tile_size}')
    if os.path.exists(detections_output_dir):
        # Remove the entire directory
        shutil.rmtree(detections_output_dir)
    os.makedirs(detections_output_dir, exist_ok=True)

    # Get all packed image files
    image_files = [f for f in os.listdir(packing_dir) if f.endswith('.jpg')]
    
    if not image_files:
        raise FileNotFoundError(f"No packed images found in {packing_dir}")

    with (open(os.path.join(detections_output_dir, 'detections.jsonl'), 'w') as f,
          open(os.path.join(detections_output_dir, 'runtimes.jsonl'), 'w') as fr):
        for image_file in tqdm.tqdm(image_files, desc=f"Processing packed images for tile size {tile_size}"):
            image_path = os.path.join(packing_dir, image_file)
            runtime = dict()
            
            # Read the packed image
            start_time = (time.time_ns() / 1e6)
            frame = cv2.imread(image_path)
            if frame is None:
                raise ValueError(f"Could not read image {image_path}")
            end_time = (time.time_ns() / 1e6)
            runtime['read'] = end_time - start_time

            # Detect objects in the frame
            start_time = (time.time_ns() / 1e6)
            outputs = polyis.models.retinanet_b3d.detect(frame, detector)
            end_time = (time.time_ns() / 1e6)
            runtime['detect'] = end_time - start_time

            # Extract bounding boxes (x1, y1, x2, y2 format)
            bounding_boxes = outputs[:, :4].tolist()

            # Save detection results
            f.write(json.dumps({ 'image_file': image_file, 'bboxes': bounding_boxes }) + '\n')
            fr.write(json.dumps(format_time(**runtime)) + '\n')


def main(args):
    """
    Main function that orchestrates the object detection process on packed images.
    
    This function serves as the entry point for the script. It:
    1. Validates the dataset directory exists
    2. Iterates through all videos in the dataset directory
    3. For each video, finds packed images for the specified tile size(s)
    4. Detects objects in each packed image using the specified detector
    5. Saves detection results as JSONL files with bounding box coordinates
    
    Args:
        args (argparse.Namespace): Parsed command line arguments containing:
            - dataset (str): Name of the dataset to process
            - tile_size (str): Tile size to use for detection ('30', '60', '120', or 'all')
            - detector (str): Name of the detector to use
            - classifier (str): Classifier name to use ('SimpleCNN', 'groundtruth', or 'all')
            - clear (bool): Whether to remove and recreate the packed_detections folder for each video
            
    Note:
        - The script expects packed images from 030_exec_pack.py in:
          {CACHE_DIR}/{dataset}/{video_file}/packing/{classifier}_{tile_size}/images/
        - Detection results are saved to:
          {CACHE_DIR}/{dataset}/{video_file}/packed_detections/{classifier}_{tile_size}/detections.jsonl
        - Each line in the output JSONL file contains one bounding box [x1, y1, x2, y2]
        - When tile_size is 'all', all available tile sizes are processed
        - When classifier is 'all', both SimpleCNN and groundtruth classifiers are processed
        - If no packed images are found for a video/tile_size/classifier combination, that combination is skipped
    """
    dataset_dir = os.path.join(CACHE_DIR, args.dataset)
    
    if not os.path.exists(dataset_dir):
        raise FileNotFoundError(f"Dataset directory {dataset_dir} does not exist")
    
    # Determine which tile sizes to process
    tile_sizes_to_process = TILE_SIZES if args.tile_size == 'all' else [int(args.tile_size)]
    
    # Determine which classifiers to process
    classifiers_to_process = ['SimpleCNN', 'groundtruth'] if args.classifier == 'all' else [args.classifier]
    
    # Get all video files from the dataset directory
    video_files = [f for f in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, f))]
    
    # Process each video file
    for video_file in sorted(video_files):
        video_file_path = os.path.join(dataset_dir, video_file)
        
        print(f"Processing video file: {video_file}")
        
        # Clear packed_detections folder if requested
        if args.clear:
            packed_detections_base_dir = os.path.join(video_file_path, 'packed_detections')
            if os.path.exists(packed_detections_base_dir):
                shutil.rmtree(packed_detections_base_dir)
                print(f"Cleared existing packed_detections folder: {packed_detections_base_dir}")
        
        # Process each classifier for this video
        for classifier in classifiers_to_process:
            print(f"Processing classifier: {classifier}")
            
            # Process each tile size for this video and classifier
            for tile_size in tile_sizes_to_process:
                if args.detector == 'retina':
                    detect_retina_packed_images(video_file_path, tile_size, classifier)
                else:
                    raise ValueError(f"Unknown detector: {args.detector}")


if __name__ == '__main__':
    main(parse_args())
