#!/usr/local/bin/python

import argparse
import json
import os
import shutil
import numpy as np
import cv2
import tqdm

CACHE_DIR = '/polyis-cache'
# TILE_SIZES = [32, 64, 128]
TILE_SIZES = [64]


def parse_args():
    """
    Parse command line arguments for the script.
    
    Returns:
        argparse.Namespace: Parsed command line arguments containing:
            - dataset (str): Dataset name to process (default: 'b3d')
            - tile_size (str): Tile size to use for unpacking (choices: '64', '128', 'all')
    """
    parser = argparse.ArgumentParser(description='Unpack detection results from packed detections generated by 040_exec_detect.py')
    parser.add_argument('--dataset', required=False,
                        default='b3d',
                        help='Dataset name')
    parser.add_argument('--tile_size', type=str, choices=['64', '128', 'all'], default='all',
                        help='Tile size to use for unpacking (or "all" for all tile sizes)')
    return parser.parse_args()


def load_mapping_file(index_map_path: str, offset_lookup_path: str):
    """
    Load mapping file that contains the index_map and offset_lookup for unpacking.
    
    Args:
        index_map_path (str): Path to the index map file
        offset_lookup_path (str): Path to the offset lookup file
        
    Returns:
        tuple[np.ndarray, dict[tuple[int, int], tuple[tuple[int, int], tuple[int, int]]]]: Mapping information containing index_map, offset_lookup, etc.
        
    Raises:
        FileNotFoundError: If index map or offset lookup file doesn't exist
        json.JSONDecodeError: If offset lookup file is invalid JSON
    """
    if not os.path.exists(index_map_path):
        raise FileNotFoundError(f"Index map file not found: {index_map_path}")
    if not os.path.exists(offset_lookup_path):
        raise FileNotFoundError(f"Offset lookup file not found: {offset_lookup_path}")
    
    index_map = np.load(index_map_path)
    with open(offset_lookup_path, 'r') as f:
        offset_lookup_str: dict = json.load(f)
    
    # Convert offset_lookup_str keys back to tuples
    offset_lookup_tuple: dict[tuple[int, int], tuple[tuple[int, int], tuple[int, int]]] = {}
    for k_str, v in offset_lookup_str.items():
        # Parse the string key back to tuple (frame_idx, group_id)
        k_str = k_str.strip('()')
        frame_idx, group_id = map(int, k_str.split(','))
        offset_lookup_tuple[(frame_idx, group_id)] = v
    
    return index_map, offset_lookup_tuple


def unpack_detections(detections: list[list[float]], index_map: np.ndarray, 
                      offset_lookup: dict[tuple[int, int], tuple[tuple[int, int], tuple[int, int]]], 
                      tile_size: int) -> tuple[dict[int, list[list[float]]], list[list[float]], list[list[float]]]:
    """
    Unpack detections from packed coordinates back to original frame coordinates.
    
    Args:
        detections (list[list[float]]): list of bounding boxes in packed coordinates [x1, y1, x2, y2]
        index_map (np.ndarray): Index map from the mapping file
        offset_lookup (dict[tuple[int, int], tuple[tuple[int, int], tuple[int, int]]]): Offset lookup from the mapping file
        tile_size (int): Size of tiles used for packing
        
    Returns:
        tuple[dict[int, list[list[float]]], list[list[float]], list[list[float]]]: dictionary mapping frame indices to lists of bounding boxes
                                                                                    in original frame coordinates, and list of detections that are not in any tile
    """
    # Initialize dictionary to store detections per frame
    frame_detections: dict[int, list[list[float]]] = {}
    not_in_any_tile_detections: list[list[float]] = []
    center_not_in_any_tile_detections: list[list[float]] = []

    # Process each detection
    for x1, y1, x2, y2 in detections:
        # Get the center point of the detection in packed coordinates
        center_x = (x1 + x2) / 2.0
        center_y = (y1 + y2) / 2.0
        
        # center, top-left, top-right, bottom-left, bottom-right
        xs = [center_x, x1, x2, x1, x2]
        ys = [center_y, y1, y1, y2, y2]

        group_id: int | None = None
        frame_idx: int | None = None
        center_in_any_tile: bool = True
        for x, y in zip(xs, ys):
            # Convert to tile coordinates in the packed image
            tile_x = int(x // tile_size)
            tile_y = int(y // tile_size)
            
            # Ensure tile coordinates are within bounds
            if (tile_y < 0 or tile_y >= index_map.shape[0] or 
                tile_x < 0 or tile_x >= index_map.shape[1]):
                continue
            
            # Get the group ID and frame index for this tile
            group_id_ = int(index_map[tile_y, tile_x, 0])
            frame_idx_ = int(index_map[tile_y, tile_x, 1])
            
            if group_id_ != 0:
                group_id = group_id_
                frame_idx = frame_idx_
                break
            center_in_any_tile = False
        
        if not center_in_any_tile:
            center_not_in_any_tile_detections.append([x1, y1, x2, y2])
        
        if group_id is None or frame_idx is None:
            not_in_any_tile_detections.append([x1, y1, x2, y2])
            continue

        # Get the offset information for this group
        if (frame_idx, group_id) not in offset_lookup:
            raise ValueError(f"No mapping info for frame {frame_idx}, group {group_id}")
        
        (packed_y, packed_x), (original_offset_y, original_offset_x) = offset_lookup[(frame_idx, group_id)]
        
        # Calculate the offset to convert from packed to original coordinates
        # The offset represents how much the tile was moved during packing
        offset_x = (original_offset_x - packed_x) * tile_size
        offset_y = (original_offset_y - packed_y) * tile_size
        
        # Convert detection back to original frame coordinates
        original_det = [
            x1 + offset_x,
            y1 + offset_y,
            x2 + offset_x,
            y2 + offset_y,
        ]
        
        # Add to frame detections
        if frame_idx not in frame_detections:
            frame_detections[frame_idx] = []
        frame_detections[frame_idx].append(original_det)
    
    return frame_detections, not_in_any_tile_detections, center_not_in_any_tile_detections


def process_video_unpacking(video_file_path: str, tile_size: int):
    """
    Process a single video for unpacking detection results.
    
    Args:
        video_file_path (str): Path to the video file directory
        tile_size (int): Tile size used for packing
    """
    print(f"Processing video {video_file_path} for unpacking")
    
    detections_file = os.path.join(video_file_path, 'packed_detections', f'proxy_{tile_size}', 'detections.jsonl')
    
    packing_dir = os.path.join(video_file_path, 'packing', f'proxy_{tile_size}')
    if not os.path.exists(packing_dir):
        raise FileNotFoundError(f"Packing directory not found: {packing_dir}")
    
    unpacked_output_dir = os.path.join(video_file_path, 'uncompressed_detections', f'proxy_{tile_size}')
    if os.path.exists(unpacked_output_dir):
        shutil.rmtree(unpacked_output_dir)
    os.makedirs(unpacked_output_dir, exist_ok=True)
    print(f"Saving unpacked detections to {unpacked_output_dir}")
    
    images_not_in_any_tile_dir = os.path.join(unpacked_output_dir, 'images_not_in_any_tile')
    os.makedirs(images_not_in_any_tile_dir, exist_ok=True)
    print(f"Saving images not in any tile to {images_not_in_any_tile_dir}")

    images_center_not_in_any_tile_dir = os.path.join(unpacked_output_dir, 'images_center_not_in_any_tile')
    os.makedirs(images_center_not_in_any_tile_dir, exist_ok=True)
    print(f"Saving images center not in any tile to {images_center_not_in_any_tile_dir}")

    # dictionary to store all frame detections
    all_frame_detections: dict[int, list[list[float]]] = {}
    
    with open(detections_file, 'r') as f:
        # Process each detection file
        for line in tqdm.tqdm(f, desc=f"Unpacking detections for tile size {tile_size}"):
            content = json.loads(line)
            image_file: str = content['image_file']

            from_idx, to_idx = image_file.split('.')[0].split('_')
            from_idx = int(from_idx)
            to_idx = int(to_idx)

            # Construct paths
            index_map_path = os.path.join(packing_dir, 'index_maps', f'{from_idx:08d}_{to_idx:08d}.npy')
            offset_lookup_path = os.path.join(packing_dir, 'offset_lookups', f'{from_idx:08d}_{to_idx:08d}.json')
            
            # Load detection results
            detections: list[list[float]] = content['bboxes']
            
            # Load corresponding mapping file
            index_map, offset_lookup = load_mapping_file(index_map_path, offset_lookup_path)
            
            # Unpack detections
            frame_detections, not_in_any_tile_detections, center_not_in_any_tile_detections = unpack_detections(detections, index_map, offset_lookup, tile_size)

            # save not_in_any_tile_detections and center_not_in_any_tile_detections
            if len(not_in_any_tile_detections) > 0:
                # load the image
                image_path = os.path.join(packing_dir, 'images', image_file)
                image = cv2.imread(image_path)
                assert image is not None, f"Image not found: {image_path}"

                # draw the detections
                for det in not_in_any_tile_detections:
                    x1, y1, x2, y2 = det
                    image = cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)

                    center_x = (x1 + x2) / 2
                    center_y = (y1 + y2) / 2
                    image = cv2.circle(image, (int(center_x), int(center_y)), 5, (0, 0, 255), -1)
                
                # save the image
                cv2.imwrite(os.path.join(images_not_in_any_tile_dir, image_file), image)

            if len(center_not_in_any_tile_detections) > 0:
                # load the image
                image_path = os.path.join(packing_dir, 'images', image_file)
                image = cv2.imread(image_path)
                assert image is not None, f"Image not found: {image_path}"

                # draw the detections
                for det in center_not_in_any_tile_detections:
                    x1, y1, x2, y2 = det
                    image = cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)

                    center_x = (x1 + x2) / 2
                    center_y = (y1 + y2) / 2
                    image = cv2.circle(image, (int(center_x), int(center_y)), 5, (0, 0, 255), -1)
                
                # save the image
                cv2.imwrite(os.path.join(images_center_not_in_any_tile_dir, image_file), image)
            
            # Merge with existing frame detections
            for frame_idx, bboxes in frame_detections.items():
                if frame_idx not in all_frame_detections:
                    all_frame_detections[frame_idx] = []
                all_frame_detections[frame_idx].extend(bboxes)
    
    # Save unpacked detections organized by frame
    # Sort frames by index
    sorted_frames = sorted(all_frame_detections.keys())
    
    # Save each frame's detections
    with open(os.path.join(unpacked_output_dir, 'detections.jsonl'), 'w') as f:
        for frame_idx in sorted_frames:
            bboxes = all_frame_detections[frame_idx]
            f.write(json.dumps({ 'frame_idx': frame_idx, 'bboxes': bboxes }) + '\n')
    
    print(f"Saved unpacked detections for {len(sorted_frames)} frames")


def main(args):
    """
    Main function that orchestrates the detection unpacking process.
    
    This function serves as the entry point for the script. It:
    1. Validates the dataset directory exists
    2. Iterates through all videos in the dataset directory
    3. For each video, finds packed detection files for the specified tile size(s)
    4. Loads corresponding mapping files and unpacks detections back to original frame coordinates
    5. Saves unpacked detections organized by frame
    
    Args:
        args (argparse.Namespace): Parsed command line arguments containing:
            - dataset (str): Name of the dataset to process
            - tile_size (str): Tile size to use for unpacking ('64', '128', or 'all')
            
    Note:
        - The script expects packed detections from 040_exec_detect.py in:
          {CACHE_DIR}/{dataset}/{video_file}/packed_detections/proxy_{tile_size}/detections/
        - The script expects mapping files from 030_exec_pack.py in:
          {CACHE_DIR}/{dataset}/{video_file}/packing/proxy_{tile_size}/images/
        - Unpacked detections are saved to:
          {CACHE_DIR}/{dataset}/{video_file}/unpacked_detections/proxy_{tile_size}/frame_{frame_idx}.jsonl
        - Each line in the output JSONL file contains one bounding box [x1, y1, x2, y2] in original frame coordinates
        - When tile_size is 'all', all available tile sizes are processed
        - If no packed detections are found for a video/tile_size combination, that combination is skipped
    """
    dataset_dir = os.path.join(CACHE_DIR, args.dataset)
    
    if not os.path.exists(dataset_dir):
        raise FileNotFoundError(f"Dataset directory {dataset_dir} does not exist")
    
    # Determine which tile sizes to process
    if args.tile_size == 'all':
        tile_sizes_to_process = TILE_SIZES
        print(f"Processing all available tile sizes: {tile_sizes_to_process}")
    else:
        tile_sizes_to_process = [int(args.tile_size)]
        print(f"Processing tile size: {tile_sizes_to_process[0]}")
    
    # Get all video files from the dataset directory
    video_files = [f for f in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, f))]
    
    if not video_files:
        print(f"No video directories found in {dataset_dir}")
        return
    
    print(f"Found {len(video_files)} video directories to process")
    
    # Process each video file
    for video_file in sorted(video_files):
        video_file_path = os.path.join(dataset_dir, video_file)
        
        print(f"\nProcessing video file: {video_file}")
        
        # Process each tile size for this video
        for tile_size in tile_sizes_to_process:
            print(f"Processing tile size: {tile_size}")
            process_video_unpacking(video_file_path, tile_size)
                


if __name__ == '__main__':
    main(parse_args())
