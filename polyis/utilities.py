import json
import os
import typing
import multiprocessing as mp

import cv2
import numpy as np
from rich import progress


DATA_RAW_DIR = '/polyis-data/video-datasets-raw'
DATA_DIR = '/polyis-data/video-datasets-low'
CACHE_DIR = '/polyis-cache'

# Define 10 distinct colors for track visualization (BGR format for OpenCV)
TRACK_COLORS = [
    (255, 0, 0),    # Blue
    (0, 255, 0),    # Green
    (0, 0, 255),    # Red
    (255, 255, 0),  # Cyan
    (255, 0, 255),  # Magenta
    (0, 255, 255),  # Yellow
    (128, 0, 255),  # Purple
    (255, 128, 0),  # Orange
    (0, 128, 255),  # Light Blue
    (255, 0, 128),  # Pink
]


def format_time(**kwargs: float | int) -> list[dict[str, float | int | str]]:
    """
    Format timing information into a list of dictionaries.
    
    Args:
        **kwargs: Keyword arguments where keys are operation names and values are timing values
        
    Returns:
        list: List of dictionaries with 'op' (operation) and 'time' keys for each input argument
        
    Example:
        >>> format_time(read=1.5, detect=2.3)
        [{'op': 'read', 'time': 1.5}, {'op': 'detect', 'time': 2.3}]
    """
    return [{'op': op, 'time': time} for op, time in kwargs.items()]


def load_detection_results(cache_dir: str, dataset: str, video_file: str, tracking: bool = False) -> list[dict]:
    """
    Load detection results from the JSONL file generated by 001_preprocess_groundtruth_detection.py.
    
    Args:
        cache_dir (str): Cache directory path
        dataset (str): Dataset name
        video_file (str): Video file name
        tracking (bool): Whether to load tracking results instead of detection results
        
    Returns:
        list[dict]: list of frame detection results
        
    Raises:
        FileNotFoundError: If no detection results file is found
    """
    file = 'tracking.jsonl' if tracking else 'detection.jsonl'
    detection_path = os.path.join(cache_dir, dataset, video_file, 'groundtruth', file)
    
    if not os.path.exists(detection_path):
        raise FileNotFoundError(f"Detection results not found: {detection_path}")
    
    print(f"Loading detection results from: {detection_path}")
    
    results = []
    with open(detection_path, 'r') as f:
        for line in f:
            if line.strip():
                results.append(json.loads(line))
    
    print(f"Loaded {len(results)} frame detections")
    return results


def load_tracking_results(cache_dir: str, dataset: str, video_file: str) -> dict[int, list[list[float]]]:
    """
    Load tracking results from the JSONL file generated by 002_preprocess_groundtruth_tracking.py.
    
    Args:
        cache_dir (str): Cache directory path
        dataset (str): Dataset name
        video_file (str): Video file name
        
    Returns:
        dict[int, list[list[float]]]: dictionary mapping frame indices to lists of tracks
        
    Raises:
        FileNotFoundError: If no tracking results file is found
    """
    tracking_path = os.path.join(cache_dir, dataset, video_file, 'groundtruth', 'tracking.jsonl')
    
    if not os.path.exists(tracking_path):
        raise FileNotFoundError(f"Tracking results not found: {tracking_path}")
    
    print(f"Loading tracking results from: {tracking_path}")
    
    frame_tracks = {}
    with open(tracking_path, 'r') as f:
        for line in f:
            if line.strip():
                frame_data = json.loads(line)
                frame_idx = frame_data['frame_idx']
                tracks = frame_data['tracks']
                frame_tracks[frame_idx] = tracks
    
    print(f"Loaded tracking results for {len(frame_tracks)} frames")
    return frame_tracks


def interpolate_trajectory(trajectory: list[tuple[int, np.ndarray]], nxt: tuple[int, np.ndarray]) -> list[tuple[int, np.ndarray]]:
    """
    Perform linear interpolation between two trajectory points except the last point (nxt).
    
    Args:
        trajectory (list[tuple[int, np.ndarray]]): list of (frame_idx, detection) tuples
        nxt (tuple[int, np.ndarray]): Next detection point (frame_idx, detection)
        
    Returns:
        list[tuple[int, np.ndarray]]: list of interpolated points
    """
    extend: list[tuple[int, np.ndarray]] = []
    
    if len(trajectory) != 0:
        prv = trajectory[-1]
        assert prv[0] < nxt[0]
        prv_det = prv[1]
        nxt_det = nxt[1]
        dif_det = nxt_det - prv_det
        dif_det = dif_det.reshape(1, -1)

        scale = np.arange(0, nxt[0] - prv[0], dtype=np.float32).reshape(-1, 1) / (nxt[0] - prv[0])
        
        int_dets = (scale @ dif_det) + prv_det.reshape(1, -1)

        for idx, int_det in enumerate(int_dets[:-1]):
            extend.append((prv[0] + idx + 1, int_det))

    return extend


def get_track_color(track_id: int) -> tuple[int, int, int]:
    """
    Get a color for a track ID by cycling through the predefined colors.
    
    Args:
        track_id (int): Track ID
        
    Returns:
        tuple[int, int, int]: BGR color tuple
    """
    color_index = track_id % len(TRACK_COLORS)
    return TRACK_COLORS[color_index]


def overlapi(interval1: tuple[int, int], interval2: tuple[int, int]):
    """
    Check if two 1D intervals overlap.
    
    Args:
        interval1 (tuple[int, int]): First interval as (start, end)
        interval2 (tuple[int, int]): Second interval as (start, end)
        
    Returns:
        bool: True if the intervals overlap, False otherwise
    """
    return (
        (interval1[0] <= interval2[0] <= interval1[1]) or
        (interval1[0] <= interval2[1] <= interval1[1]) or
        (interval2[0] <= interval1[0] <= interval2[1]) or
        (interval2[0] <= interval1[1] <= interval2[1])
    )


def overlap(b1, b2):
    """
    Check if two 2D bounding boxes overlap.
    
    Args:
        b1: First bounding box as (x1, y1, x2, y2) where (x1, y1) is top-left and (x2, y2) is bottom-right
        b2: Second bounding box as (x1, y1, x2, y2) where (x1, y1) is top-left and (x2, y2) is bottom-right
        
    Returns:
        bool: True if the bounding boxes overlap in both x and y dimensions, False otherwise
    """
    return overlapi((b1[0], b1[2]), (b2[0], b2[2])) and overlapi((b1[1], b1[3]), (b2[1], b2[3]))


def load_classification_results(cache_dir: str, dataset: str, video_file: str, tile_size: int, classifier: str) -> list:
    """
    Load classification results from the JSONL file generated by 020_exec_classify.py.
    
    Args:
        cache_dir (str): Cache directory path
        dataset (str): Dataset name
        video_file (str): Video file name
        tile_size (int): Tile size used for classification
        classifier (str): Classifier name to use

        
    Returns:
        list: List of frame classification results, each containing frame data and classifications
        
    Raises:
        FileNotFoundError: If no classification results file is found
    """
    # Look for the classification results file
    score_dir = os.path.join(cache_dir, dataset, video_file, 'relevancy', f'{classifier}_{tile_size}', 'score')
    
    # Use model scores
    expected_filename = 'score.jsonl'
    
    # Look for the specific results file
    results_file = os.path.join(score_dir, expected_filename)
    
    if not os.path.exists(results_file):
        raise FileNotFoundError(f"Classification results file not found: {results_file}")
    
    print(f"Loading classification results from: {results_file}")
    
    results = []
    with open(results_file, 'r') as f:
        for line in f:
            if line.strip():
                results.append(json.loads(line))
    
    print(f"Loaded {len(results)} frame classifications")
    return results


def create_tracker(tracker_name: str, max_age: int = 1, min_hits: int = 3, iou_threshold: float = 0.3):
    """
    Create a tracker instance based on the specified algorithm.
    
    Args:
        tracker_name (str): Name of the tracking algorithm
        max_age (int): Maximum age for SORT tracker
        min_hits (int): Minimum hits for SORT tracker
        iou_threshold (float): IOU threshold for SORT tracker
        
    Returns:
        Tracker instance
        
    Raises:
        ValueError: If the tracker name is not supported
    """
    if tracker_name == 'sort':
        print(f"Creating SORT tracker with max_age={max_age}, min_hits={min_hits}, iou_threshold={iou_threshold}")
        from modules.b3d.b3d.external.sort import Sort
        return Sort(max_age=max_age, min_hits=min_hits, iou_threshold=iou_threshold)
    else:
        raise ValueError(f"Unknown tracker: {tracker_name}")


def create_visualization_frame(frame: np.ndarray, tracks: list[list[float]], 
                             frame_idx: int, trajectory_history: dict[int, list[tuple[int, int, int]]], 
                             speed_up: int) -> np.ndarray | None:
    """
    Create a visualization frame by drawing bounding boxes and trajectories for all tracks.
    
    Args:
        frame (np.ndarray): Original video frame (H, W, 3)
        tracks (list[list[float]]): list of tracks for this frame
        frame_idx (int): Frame index for logging
        trajectory_history (dict[int, list[tuple[int, int, int]]]): History of track centers with frame timestamps
        speed_up (int): Speed up factor (process every Nth frame)
        
    Returns:
        np.ndarray | None: Frame with bounding boxes and trajectories drawn, or None if frame should be skipped
    """
    # First loop: Update trajectory history for all tracks
    for track in tracks:
        if len(track) >= 5:  # Ensure we have track_id, x1, y1, x2, y2
            track_id, x1, y1, x2, y2 = track[:5]
            track_id = int(track_id)
            
            # Calculate center of bounding box
            center_x = int((x1 + x2) // 2)
            center_y = int((y1 + y2) // 2)
            
            # Update trajectory history with frame timestamp
            if track_id not in trajectory_history:
                trajectory_history[track_id] = []
            trajectory_history[track_id].append((center_x, center_y, frame_idx))

    if frame_idx % speed_up != 0:
        return None
    
    # Create a copy of the frame for visualization
    vis_frame = frame.copy()
    
    # Second loop: Draw bounding boxes and labels for current tracks
    for track in tracks:
        if len(track) >= 5:  # Ensure we have track_id, x1, y1, x2, y2
            track_id, x1, y1, x2, y2 = track[:5]
            
            # Convert to integers for drawing
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            track_id = int(track_id)
            
            # Get color for this track
            color = get_track_color(track_id)
            
            # Draw bounding box
            cv2.rectangle(vis_frame, (x1, y1), (x2, y2), color, 2)
            
            # Draw track ID label
            label = f"ID: {track_id}"
            font_scale = 0.6
            font_thickness = 2
            
            # Calculate text size and position
            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 
                                                                 font_scale, font_thickness)
            
            # Position text above the bounding box
            text_x = x1
            text_y = max(y1 - 10, text_height + 5)
            
            # Draw text background for better visibility
            cv2.rectangle(vis_frame, (text_x - 2, text_y - text_height - 2), 
                         (text_x + text_width + 2, text_y + baseline + 2), 
                         color, -1)
            
            # Draw text
            cv2.putText(vis_frame, label, (text_x, text_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), font_thickness)
    
    # Draw all trajectories with gradual fading
    for track_id, trajectory in trajectory_history.items():
        if len(trajectory) > 1:
            color = get_track_color(track_id)
            
            # Calculate fade parameters
            max_fade_frames = 30  # Number of frames for complete fade after track ends
            current_time = frame_idx
            
            # Check if track is still active (within last 5 frames)
            track_is_active = trajectory and current_time - trajectory[-1][2] <= 5
            
            # Calculate fade alpha for the entire trajectory
            if track_is_active:
                # Track is active - full opacity
                alpha = 1.0
            else:
                # Track has ended - calculate fade based on time since last detection
                time_since_end = current_time - trajectory[-1][2]
                if time_since_end >= max_fade_frames:
                    alpha = 0.0  # Completely faded
                else:
                    alpha = 1.0 - (time_since_end / max_fade_frames)
            
            # Only draw if trajectory is still visible
            if alpha > 0.01:
                # Apply alpha to color for the entire trajectory
                line_color = tuple(int(c * alpha) for c in color)
                point_color = tuple(int(c * alpha) for c in color)
                
                # Draw trajectory lines
                for i in range(1, len(trajectory)):
                    prev_center = trajectory[i-1]
                    curr_center = trajectory[i]
                    
                    # Draw line
                    cv2.line(vis_frame, (prev_center[0], prev_center[1]), 
                             (curr_center[0], curr_center[1]), line_color, 2)
                    
                    # Draw trajectory points
                    point_radius = max(1, int(3 * alpha))
                    cv2.circle(vis_frame, (prev_center[0], prev_center[1]), point_radius, point_color, -1)
                
                # Draw final point
                final_center = trajectory[-1]
                cv2.circle(vis_frame, (final_center[0], final_center[1]), 3, point_color, -1)
    
    return vis_frame


def create_tracking_visualization(video_path: str, tracking_results: dict[int, list[list[float]]], 
                                 output_path: str, speed_up: int, process_id: int, progress_queue=None):
    """
    Create a visualization video showing tracking results overlaid on the original video.
    
    Args:
        video_path (str): Path to the input video file
        tracking_results (dict[int, list[list[float]]]): Tracking results from load_tracking_results
        output_path (str): Path where the output visualization video will be saved
    """
    print(f"Creating tracking visualization for video: {video_path}")
    
    # Open video
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Error: Could not open video {video_path}")
        return
    
    # Get video properties
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"Video info: {width}x{height}, {fps} FPS, {frame_count} frames")
    
    # Create output directory if it doesn't exist
    output_dir = os.path.dirname(output_path)
    os.makedirs(output_dir, exist_ok=True)
    
    # Create video writer
    fourcc = cv2.VideoWriter.fourcc('m', 'p', '4', 'v')
    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    if not writer.isOpened():
        print(f"Error: Could not create video writer for {output_path}")
        cap.release()
        return
    
    print(f"Creating visualization video with {frame_count} frames at {fps} FPS")
    
    # Initialize trajectory history for all tracks with frame timestamps
    trajectory_history: dict[int, list[tuple[int, int, int]]] = {}  # track_id -> [(x, y, frame_idx), ...]
    
    # Initialize frame_idx for exception handling
    frame_idx = 0
    
    # Send initial progress update
    if progress_queue is not None:
        progress_queue.put((f'cuda:{process_id}', {
            'description': os.path.basename(video_path),
            'completed': 0,
            'total': frame_count
        }))
    
    # Process each frame
    try:
        for frame_idx in range(frame_count):
            # Read frame
            ret, frame = cap.read()
            if not ret:
                break
            
            # Get tracking results for this frame
            tracks = tracking_results.get(frame_idx, [])
            
            # Create visualization frame with trajectory history
            vis_frame = create_visualization_frame(frame, tracks, frame_idx, trajectory_history, speed_up)

            # Write frame to video
            if vis_frame is not None:
                writer.write(vis_frame)
            
            # Send progress update
            if progress_queue is not None:
                progress_queue.put((f'cuda:{process_id}', {'completed': frame_idx + 1}))
    
    except KeyboardInterrupt:
        print(f"\nProcess {process_id}: KeyboardInterrupt detected. Stopping video writing...")
        print(f"Process {process_id}: Video writing stopped at frame {frame_idx}")
    except Exception as e:
        print(f"\nProcess {process_id}: Error during video processing: {e}")
    finally:
        # Release resources
        cap.release()
        writer.release()
        print(f"Process {process_id}: Resources released")
    
    print(f"Process {process_id}: Tracking visualization completed")


def mark_detections(detections: list[list[float]], width: int, height: int, chunk_size: int) -> np.ndarray:
    """
    Mark tiles as relevant based on groundtruth detections.
    
    This function creates a bitmap where 1 indicates a tile with detection and 0 indicates no detection.
    Based on the mark_detections2 function from chunker.py.
    
    Args:
        detections (list[list[float]]): List of bounding boxes, each formatted as [tracking_id, x1, y1, x2, y2]
        width (int): Frame width
        height (int): Frame height
        chunk_size (int): Size of each tile
        
    Returns:
        np.ndarray: 2D array representing the grid of tiles, where 1 indicates relevant tiles
    """
    bitmap = np.zeros((height // chunk_size, width // chunk_size), dtype=np.uint8)
    
    for bbox in detections:
        # Extract bounding box coordinates (ignore tracking_id)
        x1, y1, x2, y2 = bbox[-4:]  # Skip tracking_id at index 0
        
        # Convert to tile coordinates
        xfrom, xto = int(x1 // chunk_size), int(x2 // chunk_size)
        yfrom, yto = int(y1 // chunk_size), int(y2 // chunk_size)
        
        # Mark all tiles that overlap with the bounding box
        bitmap[yfrom:yto+1, xfrom:xto+1] = 1
    
    return bitmap


def progress_bars(command_queue: "mp.Queue", num_gpus: int, num_tasks: int,
                  refresh_per_second: float = 1):
    with progress.Progress(
        "[progress.description]{task.description}",
        progress.BarColumn(),
        "[progress.percentage]{task.percentage:>3.0f}%",
        # progress.TimeRemainingColumn(),
        progress.MofNCompleteColumn(),
        progress.TimeElapsedColumn(),
        refresh_per_second=refresh_per_second,
    ) as p:
        bars: dict[str, progress.TaskID] = {}
        overall_progress = p.add_task(f"[green]Processing {num_tasks} tasks",
                                      total=num_tasks)
        bars['overall'] = overall_progress
        for gpu_id in range(num_gpus):
            bars[f'cuda:{gpu_id}'] = p.add_task("video tilesize model T/V")

        while True:
            val = command_queue.get()
            if val is None: break
            progress_id, kwargs = val
            p.update(bars[progress_id], **kwargs)
        
        # remove all tasks
        for _, task_id in bars.items():
            p.remove_task(task_id)
        bars.clear()


class ProgressBar:
    """
    Context manager for handling progress bars with multiprocessing support.
    
    Usage:
        with ProgressBar(num_workers=4, num_tasks=100) as pb:
            # Use pb.command_queue to send progress updates
            # Use pb.worker_id_queue to manage worker IDs
            pass
    """
    
    def __init__(self, num_workers: int, num_tasks: int, refresh_per_second: float = 1):
        """
        Initialize the progress bar manager.
        
        Args:
            num_workers (int): Number of worker processes/GPUs
            num_tasks (int): Total number of tasks to process
            refresh_per_second (float): Refresh rate for progress bars
        """
        self.num_workers = num_workers
        self.num_tasks = num_tasks
        self.refresh_per_second = refresh_per_second
        
        # Initialize queues
        self.command_queue: "mp.Queue[tuple[str, dict] | None]" = mp.Queue()
        self.worker_id_queue: "mp.Queue[int]" = mp.Queue(maxsize=num_workers)
        self.progress_process: mp.Process = mp.Process(
            target=progress_bars,
            args=(self.command_queue, self.num_workers,
                  self.num_tasks, self.refresh_per_second),
            daemon=True
        )
    
    def __enter__(self):
        """Enter the context manager - set up queues and start progress process."""

        # Populate worker ID queue
        for worker_id in range(self.num_workers):
            self.worker_id_queue.put(worker_id)
        
        # Start progress bars process
        self.progress_process.start()
        
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Exit the context manager - clean up progress bars and terminate process."""
        try:
            # Signal progress bars to stop
            self.command_queue.put(None)
            
            # Wait for progress process to finish and terminate it
            self.progress_process.join(timeout=5)  # Wait up to 5 seconds
            if self.progress_process.is_alive():
                self.progress_process.terminate()
                self.progress_process.join(timeout=2)  # Give it time to terminate
            
            # Force kill if still alive
            if self.progress_process.is_alive():
                self.progress_process.kill()
                self.progress_process.join()
        except Exception as e:
            print(f"Error during progress bar cleanup: {e}")
            raise e
    
    def update_overall_progress(self, advance: int = 1):
        """Update the overall progress bar."""
        self.command_queue.put(('overall', {'advance': advance}))

    def get_worker_id(self):
        """Get a worker ID from the worker ID queue."""
        return self.worker_id_queue.get()


CLASSIFIERS_TO_TEST = [
    'SimpleCNN',
    'YoloN',
    # 'YoloS',
    'YoloM',
    # 'YoloL',
    'YoloX',
    'ShuffleNet05',
    'ShuffleNet20',
    'MobileNetL',
    'MobileNetS',
    'WideResNet50',
    'WideResNet101',
    'ResNet18', 
    'ResNet101',
    'ResNet152',
    'EfficientNetS',
    'EfficientNetL',
]